{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:16<00:00, 10534075.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import models.CNN.model as CNN\n",
    "import models.CNN.experiments as CNNexp\n",
    "import importlib\n",
    "import numpy as np\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import json\n",
    "from models.hyperparams import ImageType, LearningRule, WeightScale, Inhibition, oneHotEncode\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "from tqdm.auto import tqdm\n",
    "import itertools\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import models.learning as L\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor()])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view(h1):\n",
    "    ac1 = h1.squeeze().detach().to('cpu')\n",
    "    print(ac1.shape)\n",
    "    nbe = int(math.ceil(math.sqrt(ac1.size(0))))\n",
    "\n",
    "\n",
    "    fig, axes = plt.subplots(nbe, nbe, figsize=(20,20))\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i > ac1.size(0)-1:\n",
    "            break\n",
    "        ax.imshow(ac1[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp, lab = next(iter(test_dataloader))\n",
    "image = inp[0].permute(1,2,0)\n",
    "label = lab[0]\n",
    "input1 = inp[0].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x17688ec10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "topdown = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'models.CNN.model' from '/Users/genevievelarosedebilly/Desktop/Winter25/COMP396/HebbianTopDown/models/CNN/model.py'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(L)\n",
    "importlib.reload(CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ConfigsCNN/config0.json\", \"r\") as file:\n",
    "        config = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "186337806c534737bb9e6ac75c01f7b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "mexican_hat() got an unexpected keyword argument 'k'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m mymodelCNN \u001b[38;5;241m=\u001b[39m CNN\u001b[38;5;241m.\u001b[39mnew_CNN_Model_from_config((\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m32\u001b[39m,\u001b[38;5;241m32\u001b[39m), config, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m mymodelCNN \u001b[38;5;241m=\u001b[39m CNNexp\u001b[38;5;241m.\u001b[39mnew_CNN_Experiment(epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, mymodel\u001b[38;5;241m=\u001b[39mmymodelCNN, dataloader\u001b[38;5;241m=\u001b[39mtrain_dataloader,\n\u001b[1;32m      4\u001b[0m                                                 nclasses\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, imgtype\u001b[38;5;241m=\u001b[39mCNN\u001b[38;5;241m.\u001b[39mImageType\u001b[38;5;241m.\u001b[39mRGB, \n\u001b[1;32m      5\u001b[0m                                                 device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m), greedytrain\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m CNNexp\u001b[38;5;241m.\u001b[39mCNN_Baseline_test(mymodel\u001b[38;5;241m=\u001b[39mmymodelCNN, data_loader\u001b[38;5;241m=\u001b[39mtest_dataloader, imgtype\u001b[38;5;241m=\u001b[39mCNN\u001b[38;5;241m.\u001b[39mImageType\u001b[38;5;241m.\u001b[39mRGB, topdown\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(accuracy)\n",
      "File \u001b[0;32m~/Desktop/Winter25/COMP396/HebbianTopDown/models/CNN/experiments.py:92\u001b[0m, in \u001b[0;36mnew_CNN_Experiment\u001b[0;34m(epoch, mymodel, dataloader, nclasses, imgtype, device, greedytrain)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(layers[r_l], ConvSoftHebbLayer):\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;66;03m# if you've reached layer idx, perform forward pass with targets\u001b[39;00m\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ((r_l) \u001b[38;5;241m==\u001b[39m idx): \n\u001b[0;32m---> 92\u001b[0m         x \u001b[38;5;241m=\u001b[39m layers[r_l]\u001b[38;5;241m.\u001b[39mforward(x, target)\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m : \n\u001b[1;32m     94\u001b[0m         \u001b[38;5;66;03m# for all layers before idx, perform forward pass without targets\u001b[39;00m\n\u001b[1;32m     95\u001b[0m         x \u001b[38;5;241m=\u001b[39m layers[r_l]\u001b[38;5;241m.\u001b[39mforward(x, target\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/Winter25/COMP396/HebbianTopDown/models/CNN/layers.py:50\u001b[0m, in \u001b[0;36mConvSoftHebbLayer.forward\u001b[0;34m(self, x, target)\u001b[0m\n\u001b[1;32m     48\u001b[0m unfolded_x \u001b[38;5;241m=\u001b[39m unfolded_x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     49\u001b[0m mlp_x \u001b[38;5;241m=\u001b[39m unfolded_x\u001b[38;5;241m.\u001b[39mreshape(batch_dim \u001b[38;5;241m*\u001b[39m nb_tiles, in_dim)\n\u001b[0;32m---> 50\u001b[0m mlp_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_soft_hebb_layer(mlp_x, target)\n\u001b[1;32m     51\u001b[0m y \u001b[38;5;241m=\u001b[39m mlp_y\u001b[38;5;241m.\u001b[39mreshape(batch_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_shape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_shape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_channel)\n\u001b[1;32m     52\u001b[0m y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Winter25/COMP396/HebbianTopDown/models/MLP/layers.py:123\u001b[0m, in \u001b[0;36mSoftHebbLayer.forward\u001b[0;34m(self, x, target)\u001b[0m\n\u001b[1;32m    121\u001b[0m inference_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference(x)\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearn_weights(inference_output, target\u001b[38;5;241m=\u001b[39mtarget)\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inference_output\u001b[38;5;241m.\u001b[39my\n",
      "File \u001b[0;32m~/Desktop/Winter25/COMP396/HebbianTopDown/models/MLP/layers.py:101\u001b[0m, in \u001b[0;36mSoftHebbLayer.learn_weights\u001b[0;34m(self, inference_output, target)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn_weights\u001b[39m(\u001b[38;5;28mself\u001b[39m, inference_output, target\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    100\u001b[0m     supervised \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearningrule \u001b[38;5;241m==\u001b[39m LearningRule\u001b[38;5;241m.\u001b[39mSoftHebbOutputContrastive\n\u001b[0;32m--> 101\u001b[0m     delta_w \u001b[38;5;241m=\u001b[39m L\u001b[38;5;241m.\u001b[39mupdate_softhebb_w(inference_output\u001b[38;5;241m.\u001b[39my, inference_output\u001b[38;5;241m.\u001b[39mxn, inference_output\u001b[38;5;241m.\u001b[39ma,\n\u001b[1;32m    102\u001b[0m                                   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minhibition, inference_output\u001b[38;5;241m.\u001b[39mu, target\u001b[38;5;241m=\u001b[39mtarget,\n\u001b[1;32m    103\u001b[0m                                   supervised\u001b[38;5;241m=\u001b[39msupervised, weight_growth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight_growth, anti_hebb_factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39manti_hebb_factor)\n\u001b[1;32m    104\u001b[0m     delta_b \u001b[38;5;241m=\u001b[39m L\u001b[38;5;241m.\u001b[39mupdate_softhebb_b(inference_output\u001b[38;5;241m.\u001b[39my, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogprior, target\u001b[38;5;241m=\u001b[39mtarget, supervised\u001b[38;5;241m=\u001b[39msupervised)\n\u001b[1;32m    105\u001b[0m     delta_l \u001b[38;5;241m=\u001b[39m L\u001b[38;5;241m.\u001b[39mupdate_softhebb_lamb(inference_output\u001b[38;5;241m.\u001b[39my, inference_output\u001b[38;5;241m.\u001b[39ma, inhibition\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minhibition,\n\u001b[1;32m    106\u001b[0m                                      lamb\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlamb\u001b[38;5;241m.\u001b[39mitem(), in_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_dim, target\u001b[38;5;241m=\u001b[39mtarget,\n\u001b[1;32m    107\u001b[0m                                      supervised\u001b[38;5;241m=\u001b[39msupervised)\n",
      "File \u001b[0;32m~/Desktop/Winter25/COMP396/HebbianTopDown/models/learning.py:127\u001b[0m, in \u001b[0;36mupdate_softhebb_w\u001b[0;34m(y, normed_x, a, weights, inhibition, u, target, supervised, weight_growth, anti_hebb_factor)\u001b[0m\n\u001b[1;32m    125\u001b[0m max_values, indices \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(y_part, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# y_max\u001b[39;00m\n\u001b[1;32m    126\u001b[0m x_ratio \u001b[38;5;241m=\u001b[39m max_values \u001b[38;5;241m/\u001b[39m (y_part \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-9\u001b[39m)  \u001b[38;5;66;03m# Prevent division by zero\u001b[39;00m\n\u001b[0;32m--> 127\u001b[0m mexican_hat_factor \u001b[38;5;241m=\u001b[39m mexican_hat(x_ratio, sigma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2.0\u001b[39m, c\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m    128\u001b[0m mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(y_part, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mbool)\n\u001b[1;32m    129\u001b[0m mask\u001b[38;5;241m.\u001b[39mscatter_(\u001b[38;5;241m1\u001b[39m, indices, \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: mexican_hat() got an unexpected keyword argument 'k'"
     ]
    }
   ],
   "source": [
    "mymodelCNN = CNN.new_CNN_Model_from_config((3,32,32), config, 'cpu', 10)\n",
    "\n",
    "mymodelCNN = CNNexp.new_CNN_Experiment(epoch=1, mymodel=mymodelCNN, dataloader=train_dataloader,\n",
    "                                                nclasses=10, imgtype=CNN.ImageType.RGB, \n",
    "                                                device=torch.device('cpu'), greedytrain=True)\n",
    "    \n",
    "accuracy = CNNexp.CNN_Baseline_test(mymodel=mymodelCNN, data_loader=test_dataloader, imgtype=CNN.ImageType.RGB, topdown=False)[0]\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# greedy train -> the first 12 configs are for greedy training\n",
    "print(\"GREEDY TRAINING:\")\n",
    "\n",
    "with open(f\"ConfigsCNN/config0.json\", \"r\") as file:\n",
    "    config = json.load(file)\n",
    "\n",
    "mymodelCNN = CNN.new_CNN_Model_from_config((3,32,32), config, 'cpu', 10)\n",
    "mymodelCNN, mymodel = CNNexp.new_CNN_Experiment(epoch=1, mymodel=mymodelCNN, dataloader=train_dataloader,\n",
    "                                                nclasses=10, imgtype=CNN.ImageType.RGB, \n",
    "                                                device=torch.device('cpu'), greedytrain=True)\n",
    "    \n",
    "accuracy = CNNexp.CNN_Baseline_test(mymodel=mymodel, data_loader=test_dataloader, imgtype=CNN.ImageType.RGB, topdown=topdown)[0]\n",
    "\n",
    "mean_acc = np.mean(accuracy)\n",
    "var_acc = np.var(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u1, o1 = mymodelCNN.layers['CNNLayer1'].forward(input1, label, False)\n",
    "u2, o2 = mymodelCNN.layers['CNNLayer2'].forward(o1, None, False)\n",
    "u3, o3 = mymodelCNN.layers['CNNLayer3'].forward(o2, None, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view(o1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view(o2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view(o3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Classifier Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"modelconfig.json\", \"r\") as file:\n",
    "        config = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodelCNN = CNN.CNN_Model_from_config((3,32,32), config, LearningRule.SoftHebb, WeightScale.No, LearningRule.SoftHebb, Inhibition.Softmax, 'cpu', 10)\n",
    "mymodelCNN, mymodel = CNN.CNN_Experiment(epoch=1, mymodel=mymodelCNN, dataloader=train_dataloader, testloader= test_dataloader,\n",
    "                                         dataset='CIFAR10',\n",
    "                                      nclasses=10, imgtype=CNN.ImageType.RGB, traintopdown=topdown, testtopdown=topdown, device=torch.device('cpu'), greedytrain=True)\n",
    "# print(CNN.CNN_Baseline_test(mymodel=mymodelCNN, data_loader=test_dataloader, imgtype=CNN.ImageType.RGB,\n",
    "#                                 topdown=topdown))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(CNN.CNN_Baseline_test(mymodel=mymodel, data_loader=test_dataloader, imgtype=CNN.ImageType.RGB,\n",
    "                                topdown=topdown))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "u1, o1 = mymodelCNN.layers['CNNLayer1'].forward(input1, label, False)\n",
    "u2, o2 = mymodelCNN.layers['CNNLayer2'].forward(o1, None, False)\n",
    "u3, o3 = mymodelCNN.layers['CNNLayer3'].forward(o2, None, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view(o1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view(o2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view(o3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hebbian Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "myHebbmodel = CNN.Hebbian_Classifier(8192, 10, 'cpu', mymodelCNN, 0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(50):\n",
    "    for data in tqdm(test_dataloader):\n",
    "        inputs, label = data\n",
    "        myHebbmodel.train_classifier(inputs, oneHotEncode(label, 10, 'cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a7c3ae6699e4ccca4c68218a918471f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.2927, {3: (22, 1000, 51), 6: (526, 1000, 1643), 8: (474, 1000, 825), 0: (570, 1000, 1467), 1: (245, 1000, 447), 4: (330, 1000, 1227), 5: (305, 1000, 600), 9: (322, 1000, 623), 7: (131, 1000, 188), 2: (2, 1000, 2)})\n"
     ]
    }
   ],
   "source": [
    "print(CNN.CNN_Baseline_test(mymodel=myHebbmodel, data_loader=test_dataloader, imgtype=CNN.ImageType.RGB,\n",
    "                                topdown=topdown))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient 64 - 256 - 1024 channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"fourconfig.json\", \"r\") as file:\n",
    "        config = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodelCNN = CNN.CNN_Model_from_config((3,32,32), config, LearningRule.SoftHebb, WeightScale.No, LearningRule.SoftHebb, Inhibition.Softmax, 'cpu', 10)\n",
    "mymodelCNN, mymodel = CNN.CNN_Experiment(epoch=1, mymodel=mymodelCNN, dataloader=train_dataloader, testloader= test_dataloader,\n",
    "                                         dataset='CIFAR10',\n",
    "                                      nclasses=10, imgtype=CNN.ImageType.RGB, traintopdown=topdown, testtopdown=topdown, device=torch.device('cpu'), greedytrain=True)\n",
    "# print(CNN.CNN_Baseline_test(mymodel=mymodel, data_loader=test_dataloader, imgtype=CNN.ImageType.RGB,\n",
    "#                                 topdown=topdown))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(CNN.CNN_Baseline_test(mymodel=mymodel, data_loader=test_dataloader, imgtype=CNN.ImageType.RGB,\n",
    "                                topdown=topdown))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u1, o1 = mymodelCNN.layers['CNNLayer1'].forward(input1, label, False)\n",
    "u2, o2 = mymodelCNN.layers['CNNLayer2'].forward(o1, None, False)\n",
    "u3, o3 = mymodelCNN.layers['CNNLayer3'].forward(o2, None, False)\n",
    "u4, o4 = mymodelCNN.layers['CNNLayer4'].forward(o3, None, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view(o1)\n",
    "view(o2)\n",
    "view(o3)\n",
    "view(o4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(CNN.CNN_Baseline_test(mymodel=mymodel, data_loader=test_dataloader, imgtype=CNN.ImageType.RGB,\n",
    "                                topdown=topdown))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "u1, o1 = mymodelCNN.layers['CNNLayer1'].forward(input1, label, False)\n",
    "u2, o2 = mymodelCNN.layers['CNNLayer2'].forward(o1, None, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view(o1)\n",
    "view(o2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(CNN.CNN_Baseline_test(mymodel=mymodel, data_loader=test_dataloader, imgtype=CNN.ImageType.RGB,\n",
    "                                topdown=topdown))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "u1, o1 = mymodelCNN.layers['CNNLayer1'].forward(input1, label, False)\n",
    "u2, o2 = mymodelCNN.layers['CNNLayer2'].forward(o1, None, False)\n",
    "u3, o3 = mymodelCNN.layers['CNNLayer3'].forward(o2, None, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view(o1)\n",
    "view(o2)\n",
    "view(o3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
