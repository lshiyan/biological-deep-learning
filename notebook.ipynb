{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments.mlp import MLPExperiment\n",
    "from layers.hebbian_layer import HebbianLayer\n",
    "from models.hebbian_network import HebbianNetwork\n",
    "import torch\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment=MLPExperiment(None, 784, 64 , 10, lamb=15, num_epochs=3, heb_lr=0.005, eps=0.01)\n",
    "experiment.train()\n",
    "experiment.visualizeWeights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies=[]\n",
    "active=[]\n",
    "l_array=range(1,16)\n",
    "for l in l_array:\n",
    "    experiment=MLPExperiment(None, 784, 64 , 10, lamb=l, num_epochs=3, heb_lr=0.005, eps=0.01)\n",
    "    experiment.train()\n",
    "    accuracies.append(experiment.test())\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1,16), [0.7366, 0.6646, 0.5984, 0.6185, 0.7169, 0.6164, 0.6315, 0.6471, 0.7368, 0.7025, 0.5883, 0.7298, 0.694, 0.6424, 0.6855], label=\"MNIST\")\n",
    "plt.plot(range(1,16), accuracies, label=\"Fashion-MNIST\")\n",
    "plt.plot()\n",
    "plt.xlabel(\"Lambda\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(loc='bottom ')\n",
    "plt.title(\"Model Accuracy vs Lambda Value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_classifier_weight=experiment.model.classifier_layer.fc.weight\n",
    "model_feature_selectors=experiment.model.hebbian_layer.fc.weight\n",
    "\n",
    "fig, axes = plt.subplots(10, 3, figsize=(16, 40))\n",
    "\n",
    "for i in range(10):\n",
    "    top_3 = torch.topk(model_classifier_weight[i], 3).indices\n",
    "    for j in range(3):\n",
    "        ele = top_3[j]\n",
    "        feature_selector = model_feature_selectors[ele]  # This line might need correction\n",
    "        heatmap = feature_selector.view(int(math.sqrt(feature_selector.size(0))), int(math.sqrt(feature_selector.size(0))))\n",
    "        ax = axes[i, j]\n",
    "        im = ax.imshow(heatmap, cmap='hot', interpolation='nearest')\n",
    "        fig.colorbar(im, ax=ax)\n",
    "        ax.set_title(f'Weight {ele}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.visualizeWeights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.visualizeWeights(10, classifier=1)\n",
    "print(experiment.model.classifier_layer.fc.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
