{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# PART 1: Imports\n",
    "##############################################################################\n",
    "\n",
    "# Built-in imports\n",
    "import logging\n",
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "from operator import itemgetter\n",
    "from pathlib import Path\n",
    "\n",
    "# Pytorch imports\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.distributed as dist\n",
    "from torch import nn\n",
    "from torch.nn.functional import one_hot\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Custom defined model imports\n",
    "from models.hebbian_network import HebbianNetwork # Model import\n",
    "\n",
    "# Utils imports\n",
    "from utils.experiment_logger import *\n",
    "from utils.experiment_parser import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# PART 2: Create logs for experiment\n",
    "##############################################################################\n",
    "\n",
    "# Setup the result folder\n",
    "EXP_NUM = 'cpu-1'\n",
    "RESULT_PATH = f\"results/experiment-{EXP_NUM}\"\n",
    "\n",
    "if not os.path.exists(RESULT_PATH):\n",
    "    os.makedirs(RESULT_PATH, exist_ok=True)\n",
    "    print(f\"Experiment {EXP_NUM} result folder created successfully.\")\n",
    "else:\n",
    "    try:\n",
    "        shutil.rmtree(RESULT_PATH)\n",
    "        print(f\"Removed {RESULT_PATH}.\")\n",
    "        os.makedirs(RESULT_PATH, exist_ok=True)\n",
    "        print(f\"Experiment {EXP_NUM} result folder re-created successfully.\")\n",
    "    except OSError as e:\n",
    "        print(f\"Error: {e.strerror}\")\n",
    "\n",
    "# Create logs\n",
    "PRINT_LOG = get_print_log(\"Print Log\", RESULT_PATH) # Replace print statements (for debugging purposes)\n",
    "TEST_LOG = get_test_log(\"Test Log\", RESULT_PATH) # Test accuracy\n",
    "PARAM_LOG = get_parameter_log(\"Parameter Log\", RESULT_PATH) # Experiment parameters\n",
    "DEBUG_LOG = get_debug_log(\"Debug Log\", RESULT_PATH) # Debugging stuff\n",
    "EXP_LOG = get_experiment_log(\"Experiment Log\", RESULT_PATH) # Logs during experiment\n",
    "\n",
    "\n",
    "EXP_LOG.info(\"Completed imports.\")\n",
    "EXP_LOG.info(\"Completed log setups.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# PART 3: Parse arguments for the experiment\n",
    "##############################################################################\n",
    "\n",
    "EXP_LOG.info(\"Started arguments setup.\")\n",
    "\n",
    "# Simulate the command line arguments\n",
    "args_dict = {\n",
    "    '--is_training': True,\n",
    "    '--data_name': 'MNIST',\n",
    "    '--train_data': 'data/mnist/train-images.idx3-ubyte',\n",
    "    '--train_label': 'data/mnist/train-labels.idx1-ubyte',\n",
    "    '--test_data': 'data/mnist/t10k-images.idx3-ubyte',\n",
    "    '--test_label': 'data/mnist/t10k-labels.idx1-ubyte',\n",
    "    '--train_filename': 'data/mnist/mnist_train.csv',\n",
    "    '--test_filename': 'data/mnist/mnist_test.csv',\n",
    "    '--input_dim': 784,\n",
    "    '--heb_dim': 64,\n",
    "    '--output_dim': 10,\n",
    "    '--heb_lamb': 15,\n",
    "    '--heb_gam': 0.99,\n",
    "    '--cla_lamb': 1,\n",
    "    '--eps': 0.01,\n",
    "    '--epochs': 3,\n",
    "    '--test-epochs': 1,\n",
    "    '--dropout': 0.2,\n",
    "    '--lr': 0.005,\n",
    "    '--lr-step-size': 1000,\n",
    "    '--gamma': 1,\n",
    "    '--batch-size': 1,\n",
    "    '--device-id': 'cpu'\n",
    "}\n",
    "\n",
    "# Convert the dictionary to a list of arguments\n",
    "args_list = []\n",
    "for k, v in args_dict.items():\n",
    "    args_list.append(k)\n",
    "    args_list.append(str(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# PART 4: Helper functions\n",
    "##############################################################################\n",
    "def get_optimizer(model):\n",
    "    optimizer = optim.Adam(model.get_module(\"Hebbian Layer\").parameters(), 0.001)\n",
    "    return optimizer\n",
    "\n",
    "def get_loss_function():\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    return loss_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# PART 5: Training\n",
    "##############################################################################\n",
    "\"\"\"\n",
    "Method defining how a single training epoch works\n",
    "@param\n",
    "    model (models.Network) = the network that is being trained\n",
    "    train_data_loader (torch.DataLoader) = dataloader with the training data\n",
    "    device (str) = name of device on which computations will be done\n",
    "    optimizer (torch.Optim) = optimizer for \n",
    "@return\n",
    "    ___ (void) = no returns\n",
    "\"\"\"\n",
    "def train_loop(model, train_data_loader, device):\n",
    "    model.train()\n",
    "    \n",
    "    EXP_LOG.info(\"Set the model to training mode.\")\n",
    "\n",
    "    for inputs, labels in train_data_loader:\n",
    "        inputs, labels = inputs.to(device).float(), one_hot(labels, 10).squeeze().to(device).float()\n",
    "\n",
    "        #EXP_LOG.info(f\"Sent inputs and labels to specified device ({device}).\")\n",
    "\n",
    "        model(inputs, clamped_output=labels)\n",
    "\n",
    "        #EXP_LOG.info(f\"The inputs and labels passed through model for training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# PART 6: Testing\n",
    "##############################################################################\n",
    "\"\"\"\n",
    "Method that test the model at certain epochs during the training process\n",
    "@param\n",
    "    model (models.Network) = model to be trained\n",
    "    test_data_loader (torch.DataLoader) = dataloader containing the testing dataset\n",
    "    device (str) = name of device on which computations will be done\n",
    "    epoch (int) = epoch number training is at\n",
    "@return\n",
    "    correct/total (float) = accuracy of the model\n",
    "\"\"\"\n",
    "def test_loop(model, test_data_loader, device, epoch):\n",
    "    EXP_LOG.info(\"Started 'test_loop' function.\")\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    EXP_LOG.info(\"Set the model to testing mode.\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        seen = 0\n",
    "        total = len(test_data_loader.dataset)\n",
    "\n",
    "        for inputs, labels in test_data_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            #EXP_LOG.info(f\"Sent inputs and labels to specified device ({device}).\")\n",
    "\n",
    "            predictions = model(inputs)\n",
    "\n",
    "            EXP_LOG.info(f\"The inputs were put into the model ({labels.item()}) and {predictions.argmax(1).item()} are the predictions.\")\n",
    "\n",
    "            correct += (predictions.argmax(1) == labels).type(torch.float).sum().item()\n",
    "            seen += len(labels)\n",
    "\n",
    "            EXP_LOG.info(f\"The number of correct predictions until now: {correct} out of {seen}.\")\n",
    "\n",
    "        EXP_LOG.info(f\"Completed testing with {correct} out of {seen}.\")\n",
    "        EXP_LOG.warning(f\"Check if seen ({seen}) is same as total ({total})\")\n",
    "        TEST_LOG.info(f'Epoch Number: {epoch} || Test Accuracy: {correct/total}') \n",
    "        EXP_LOG.info(\"Completed 'test_loop' function.\")\n",
    "        \n",
    "        return correct / total\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Method to test the model on the entire testing dataset\n",
    "@param\n",
    "    model (models.Network) = ML model to be tested\n",
    "    test_data_loader (torch.DataLoader) = testing data loader that model will be tested on\n",
    "    device (str) = name of device on which computations will be done\n",
    "@return\n",
    "    correct/total (float) = accuracy of the model\n",
    "\"\"\"\n",
    "def model_test(model, test_data_loader, device):\n",
    "    EXP_LOG.info(\"Started 'model_test' function.\")\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    EXP_LOG.info(\"Set the model to testing mode.\")\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_data_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            #EXP_LOG.info(f\"Sent inputs and labels to specified device ({device}).\")\n",
    "\n",
    "            predictions = model(inputs)\n",
    "\n",
    "            EXP_LOG.info(f\"The inputs were put into the model ({labels.item()}) and {predictions.argmax(1).item()} are the predictions.\")\n",
    "\n",
    "            correct += (predictions.argmax(1) == labels).type(torch.float).sum().item()\n",
    "            total += len(labels)\n",
    "\n",
    "            EXP_LOG.info(f\"The number of correct predictions until now: {correct} out of {total}.\")\n",
    "\n",
    "        EXP_LOG.info(f\"Completed testing with {correct} out of {total}.\")\n",
    "        EXP_LOG.info(\"Completed 'model_test' function.\")\n",
    "\n",
    "        return correct / total\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Method to test the model on the entire testing dataset\n",
    "@param\n",
    "    model (models.Network) = ML model to be tested\n",
    "    test_data_loader (torch.DataLoader) = testing data loader that model will be tested on\n",
    "    device (str) = name of device on which computations will be done\n",
    "@return\n",
    "    correct/total (float) = accuracy of the model\n",
    "\"\"\"\n",
    "def testing(model, test_data_loader, device):\n",
    "    EXP_LOG.info(\"Started 'testing' function.\")\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    EXP_LOG.info(\"Set the model to testing mode.\")\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_data_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            #EXP_LOG.info(f\"Send {len(inputs)} inputs and {len(labels)} labels to specified device ({device}).\")\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            predicted = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            EXP_LOG.info(f\"The inputs were put into the model ({labels.item()}) and {predicted.item()} are the predictions.\")\n",
    "\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += len(labels)                                             \n",
    "\n",
    "            EXP_LOG.info(f\"The number of correct predictions until now: {correct} out of {total}.\")\n",
    "        \n",
    "        EXP_LOG.info(f\"Completed testing with {correct} out of {total}.\")\n",
    "        EXP_LOG.info(\"Completed 'testing' function.\")\n",
    "\n",
    "        return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# PART 7: Main Function\n",
    "##############################################################################\n",
    "\"\"\"\n",
    "Method describing the main part of the code -> how experiment will be ran\n",
    "@param\n",
    "    args (argparse.ArgumentParser) = arguments passed to the main function\n",
    "@return\n",
    "    ___ (void) = no returns\n",
    "\"\"\"\n",
    "def main(args):\n",
    "    # ===========================================\n",
    "    # Distributed Training Configuration\n",
    "    # ===========================================\n",
    "    args.device_id = 'cpu'\n",
    "    torch.device(args.device_id)\n",
    "\n",
    "\n",
    "    # ===========================================\n",
    "    # Set up model\n",
    "    # ===========================================\n",
    "    model = HebbianNetwork(args).float()\n",
    "    model = model.to(args.device_id)\n",
    "    EXP_LOG.info(\"Created model for the experiment.\")\n",
    "\n",
    "\n",
    "    # ===========================================\n",
    "    # Set up datasets for training and testing purposes\n",
    "    # ===========================================\n",
    "    \n",
    "    # Training dataset\n",
    "    train_data_set = model.get_module(\"Input Layer\").setup_train_data()\n",
    "    train_data_loader = DataLoader(train_data_set, batch_size=args.batch_size, shuffle=True)\n",
    "    EXP_LOG.info(\"Completed setup for training dataset and dataloader.\")\n",
    "\n",
    "    # Testing dataset\n",
    "    test_data_set = model.get_module(\"Input Layer\").setup_test_data()\n",
    "    test_data_loader = DataLoader(test_data_set, batch_size=args.batch_size, shuffle=True)\n",
    "    EXP_LOG.info(\"Completed setup for testing dataset and dataloader.\")\n",
    "\n",
    "\n",
    "    # ===========================================\n",
    "    # Training and testing process\n",
    "    # ===========================================\n",
    "   \n",
    "    # Loops through each epoch from current epoch to total number of epochs\n",
    "    EXP_LOG.info(\"Started training and testing loops.\")\n",
    "    \n",
    "    for epoch in range(0, args.epochs): \n",
    "        train_loop(\n",
    "            model, \n",
    "            train_data_loader, \n",
    "            args.device_id,\n",
    "        )\n",
    "\n",
    "        test_loop(\n",
    "            model,\n",
    "            test_data_loader,\n",
    "            args.device_id,\n",
    "            epoch\n",
    "        )\n",
    "\n",
    "    EXP_LOG.info(\"Completed training of model.\")\n",
    "\n",
    "    model.visualize_weights(RESULT_PATH)\n",
    "\n",
    "    EXP_LOG.info(\"Visualize weights of model after training.\")\n",
    "\n",
    "    accuracy_1 = test_loop(model, test_data_loader, args.device_id, args.epochs)\n",
    "    accuracy_2 = model_test(model, test_data_loader, args.device_id)\n",
    "    accuracy_3 = testing(model, test_data_loader, args.device_id)\n",
    "\n",
    "    EXP_LOG.info(\"Completed all 3 different testing methods.\")\n",
    "\n",
    "    PARAM_LOG.info(f\"Accuracy 1 of model after training for {args.epochs} epochs: {accuracy_1}\")\n",
    "    PARAM_LOG.info(f\"Accuracy 2 of model after training for {args.epochs} epochs: {accuracy_2}\")\n",
    "    PARAM_LOG.info(f\"Accuracy 3 of model after training for {args.epochs} epochs: {accuracy_3}\")\n",
    "\n",
    "    EXP_LOG.info(\"Experiment Completed!!!\")\n",
    "\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# PART 8: What code will be ran when file is ran\n",
    "##############################################################################\n",
    "\n",
    "# Actual code that will be ran\n",
    "args = parse_arguments(args_list)\n",
    "EXP_LOG.info(\"Completed arguments' parsing.\")\n",
    "\n",
    "# Logging training parameters\n",
    "if os.path.getsize(RESULT_PATH+'/parameters.log') == 0:\n",
    "    EXP_LOG.info(\"Started logging of experiment parameters.\")\n",
    "    PARAM_LOG.info(f\"Input Dimension: {args.input_dim}\")\n",
    "    PARAM_LOG.info(f\"Hebbian Layer Dimension: {args.heb_dim}\")\n",
    "    PARAM_LOG.info(f\"Outout Dimension: {args.output_dim}\")\n",
    "    PARAM_LOG.info(f\"Hebbian Layer Lambda: {args.heb_lamb}\")\n",
    "    PARAM_LOG.info(f\"Hebbian Layer Gamma: {args.heb_gam}\")\n",
    "    PARAM_LOG.info(f\"Classification Layer Lambda: {args.cla_lamb}\")\n",
    "    PARAM_LOG.info(f\"Network Learning Rate: {args.lr}\")\n",
    "    PARAM_LOG.info(f\"Epsilon: {args.eps}\")\n",
    "    PARAM_LOG.info(f\"Number of Epochs: {args.epochs}\")\n",
    "    EXP_LOG.info(\"Completed logging of experiment parameters.\")\n",
    "\n",
    "# Logging start of experiment\n",
    "EXP_LOG.info(\"Start of experiment.\")\n",
    "\n",
    "# Run experiment\n",
    "main(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
